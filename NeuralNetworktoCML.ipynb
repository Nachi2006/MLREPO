{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNXK6rDynyO4uM12h5Ljpd+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nachi2006/MLREPO/blob/main/NeuralNetworktoCML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vn8rGlHa5YjK",
        "outputId": "989d6a54-eb2a-4c2e-df91-496ee752b3a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading and preparing the Iris dataset...\n",
            "Training the model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:coremltools:When both 'convert_to' and 'minimum_deployment_target' not specified, 'convert_to' is set to \"mlprogram\" and 'minimum_deployment_target' is set to ct.target.iOS15 (which is same as ct.target.macOS12). Note: the model will not run on systems older than iOS15/macOS12/watchOS8/tvOS15. In order to make your model run on older system, please set the 'minimum_deployment_target' to iOS14/iOS13. Details please see the link: https://apple.github.io/coremltools/docs-guides/source/target-conversion-formats.html\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training complete.\n",
            "------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Converting PyTorch Frontend ==> MIL Ops:  67%|██████▋   | 2/3 [00:00<00:00, 1170.45 ops/s]\n",
            "Running MIL frontend_pytorch pipeline: 100%|██████████| 5/5 [00:00<00:00, 3926.52 passes/s]\n",
            "Running MIL default pipeline: 100%|██████████| 89/89 [00:00<00:00, 2899.34 passes/s]\n",
            "Running MIL backend_mlprogram pipeline: 100%|██████████| 12/12 [00:00<00:00, 3695.96 passes/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch model successfully converted and saved as iris_net.mlpackage\n",
            "------------------------------\n"
          ]
        }
      ],
      "source": [
        "# This script demonstrates how to create a PyTorch model and convert it to a Core ML .mlpackage file.\n",
        "\n",
        "# First, make sure you have the necessary libraries installed.\n",
        "# pip install torch coremltools scikit-learn numpy\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import coremltools as ct\n",
        "import warnings\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torch.optim import SGD\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Suppress warnings that might appear during conversion.\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "# Step 1: Define a simple PyTorch model for the Iris dataset.\n",
        "# The Iris dataset has 4 features and 3 classes.\n",
        "class IrisNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(IrisNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(4, 16)  # Input layer with 4 features, hidden layer with 16 neurons\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(16, 3)   # Hidden layer to output layer with 3 classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Instantiate the model and set it to evaluation mode.\n",
        "# This is crucial for conversion as it disables things like dropout layers.\n",
        "model = IrisNet()\n",
        "model.eval()\n",
        "\n",
        "# Step 2: Load and preprocess the Iris dataset.\n",
        "print(\"Loading and preparing the Iris dataset...\")\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert numpy arrays to PyTorch tensors.\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "dataloader = DataLoader(dataset, batch_size=10, shuffle=True)\n",
        "optimizer = SGD(model.parameters(), lr=0.01)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Step 3: Train the model for a few epochs.\n",
        "print(\"Training the model...\")\n",
        "for epoch in range(50):\n",
        "    for inputs, labels in dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "print(\"Training complete.\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# Step 4: Create a dummy input tensor for tracing.\n",
        "# The shape must match the expected input of the model. Here, it's a single sample with 4 features.\n",
        "dummy_input = torch.tensor(X_test[0:1], dtype=torch.float32)\n",
        "\n",
        "# Step 5: Trace the model using torch.jit.trace.\n",
        "# This step creates a TorchScript representation of the model's graph.\n",
        "traced_model = torch.jit.trace(model, dummy_input)\n",
        "\n",
        "# Step 6: Convert the traced PyTorch model to Core ML.\n",
        "# We use the ct.convert() function and specify the input type.\n",
        "# The `inputs` parameter is a list of ct.TensorType or ct.ImageType.\n",
        "coreml_model = ct.convert(\n",
        "    traced_model,\n",
        "    inputs=[ct.TensorType(shape=dummy_input.shape)]\n",
        ")\n",
        "\n",
        "# Step 7: Save the Core ML model to a file.\n",
        "# Newer versions of coremltools default to the \"mlprogram\" format, which uses the .mlpackage extension.\n",
        "# We will use .mlpackage as it is the recommended and modern format.\n",
        "coreml_model.save(\"iris_net.mlpackage\")\n",
        "\n",
        "print(\"PyTorch model successfully converted and saved as iris_net.mlpackage\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# The verification step has been removed as `coreml_model.predict()` is not supported in this environment.\n",
        "# To verify the conversion, you would need to load the generated .mlpackage file on a macOS system\n",
        "# or an iOS/iPadOS device and run a prediction with it."
      ]
    }
  ]
}